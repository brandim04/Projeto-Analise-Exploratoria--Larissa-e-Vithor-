## üìÑ Arquivo README.md

Aqui est√° o arquivo **README.md** completo, formatado em Markdown, consolidando o projeto de pr√©-processamento de dados.

---

### üë• Nome dos Integrantes

* [Larissa Brandim]
* [Vithor Gabriel]

---

### üîó Link da Base de Dados Utilizada

A base de dados utilizada √© o **Olist E-Commerce Public Dataset**, uma cole√ß√£o de dados reais de pedidos feitos na Olist Store, no Brasil.

* **Link:** https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce

---

### üéØ Objetivo do Projeto

O objetivo principal deste projeto foi **limpar, integrar e pr√©-processar** m√∫ltiplos *datasets* de e-commerce para criar um √∫nico arquivo de dados transacionais, pronto para ser utilizado em tarefas de **an√°lise avan√ßada** e **modelagem preditiva** (ex: previs√£o de entrega, an√°lise de satisfa√ß√£o e *clustering*).

---

### üõ†Ô∏è Descri√ß√£o do Processo de Tratamento dos Dados

O processo de tratamento seguiu um rigoroso **Pipeline de Pr√©-processamento** (Item 12), garantindo integridade dos dados para an√°lises e modelos.

---

#### 1. Limpeza e Padroniza√ß√£o Inicial (Itens 5, 6, 7)

- **Convers√£o de Tipos:** Todas as colunas de data/hora (`object`) foram convertidas para `datetime64[ns]`.
- **Padroniza√ß√£o de Texto:** Colunas categ√≥ricas (ex: `order_status`) foram padronizadas com `.str.title()`.
- **Tratamento de Duplicatas e NaNs:**  
  - Remo√ß√£o de linhas duplicadas  
  - Imputa√ß√£o da **mediana** para valores ausentes em colunas num√©ricas (ex: dimens√µes de produtos)

---

#### 2. Tratamento de Outliers (Item 5.4)

- **Identifica√ß√£o por Z-score:** Outliers foram identificados nas vari√°veis `price` e `product_weight_g`.
- **Decis√£o:** Mantivemos os outliers, pois representam transa√ß√µes reais e s√£o importantes para an√°lises de receita e log√≠stica.

---

#### 3. Engenharia de Features (Item 11)

Foram criados atributos essenciais para a an√°lise de e-commerce:

- `total_value` ‚Äî Pre√ßo total do item (Pre√ßo + Frete)
- `freight_ratio` ‚Äî Raz√£o Frete/Pre√ßo
- `shipping_month` e `shipping_year` ‚Äî Extra√ß√£o temporal
- `price_category` ‚Äî Faixas de pre√ßo: 'Muito Barato', 'Barato', 'Normal', 'Caro', 'Muito Caro'

---

#### 4. Codifica√ß√£o e Scaling (Itens 8, 9)

- **Codifica√ß√£o Categ√≥rica:** One-Hot Encoding via `pd.get_dummies()`
- **Normaliza√ß√£o:**  
  - MinMaxScaler aplicado a `price`

---

#### 5. Sele√ß√£o de Atributos (Item 10)

- **Baixa Vari√¢ncia:** Remo√ß√£o de colunas quase constantes
- **Remo√ß√£o de IDs:** `order_id`, `customer_id` etc., por n√£o terem valor preditivo
- **Correla√ß√£o:** Avaliada especialmente entre `price` e `freight_value`

---

### üöß Principais Desafios Encontrados

1. **Integra√ß√£o de M√∫ltiplos Arquivos:** Unifica√ß√£o correta dos 8 *datasets* exigiu aten√ß√£o √†s chaves.
2. **Datas e NaNs:** Pedidos incompletos/cancelados geraram valores `NaT` complexos de tratar.
3. **Alta Cardinalidade:** *Features* como `product_id` foram removidas devido ao alto custo computacional.

---

### üìä Principais Conclus√µes

- A rela√ß√£o **Pre√ßo vs. Frete** mostrou impacto direto nos custos log√≠sticos.
- A categoriza√ß√£o de pre√ßo ajudou a suavizar distribui√ß√µes assim√©tricas.
- O pr√©-processamento resultou em um *dataset* altamente confi√°vel, vi√°vel para an√°lises como:
  - previs√£o de entregas  
  - estudo de satisfa√ß√£o  
  - KPIs de neg√≥cio  

---

### üìÅ Arquivo CSV Final

O arquivo gerado ao final do processo foi:

**`olist_ecommerce_cleaned_processed.csv`**

Esse arquivo cont√©m todos os dados integrados, limpos, transformados e prontos para an√°lises avan√ßadas ou Machine Learning.

---
